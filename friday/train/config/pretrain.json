{
    "model": {
      "language_model": {
        "model_name_or_path": "microsoft/Phi-4-mini-reasoning",
        "tokenizer_name_or_path": "kevin510/friday",
        "freeze": true,
        "tokenizer_params": {
            "max_length": 2048,
            "padding_side": "right",
            "use_fast": true,
            "trust_remote_code": true,
        },
        "model_params": {
            "use_cache": false,
        }
      },
      "vision_tower": {
        "model_name_or_path": "google/siglip2-base-patch16-384",
        "use_s2": true,
        "s2_scales": "384,768",
        "freeze": true
      },
      "vision_adapter": {
        "hidden_dim": 1024,
        "num_layers": 2,
        "activation": "gelu",
        "checkpoint_path": null,
        "freeze": true
      }
    },
    "training": {
        "local_rank": -1,
        "device": "cuda",
        "cache_dir": null,
        "optim": "adamw_torch",
        "remove_unused_columns": false,
        "freeze_mm_mlp_adapter": false,
        "mpt_attn_impl": "triton",
        "bf16": true,
        "bits": 16,
        "bits_and_bytes_params": {
            "llm_int8_skip_modules": ["mm_projector"],
            "llm_int8_threshold": 6.0,
            "llm_int8_has_fp16_weight": false,
            "bnb_4bit_use_double_quant": true,
            "bnb_4bit_quant_type": "nf4"
        },
        "lora_enable": false,
        "lora_params": {
            "r": 64,
            "alpha": 16,
            "dropout": 0.05,
            "bias": "none",
            "weight_path": "",
        },
        "mm_projector_lr": null,
        "group_by_modality_length": false,
        "output_dir": "./checkpoints-pretrain/friday",
        "num_train_epochs": 1,
        "per_device_train_batch_size": 8,
        "per_device_eval_batch_size": 8,
        "gradient_accumulation_steps": 4,
        "evaluation_strategy": "no",
        "save_strategy": "steps",
        "save_steps": 24000,
        "save_total_limit": 1,
        "learning_rate": 5e-4,
        "weight_decay": 0.01,
        "warmup_ratio": 0.03,
        "lr_scheduler_type": "cosine",
        "logging_steps": 1,
        "tf32": true,
        "gradient_checkpointing": true,
        "dataloader_num_workers": 4,
        "lazy_preprocess": true

    },
    "data": {
        "conversation_template": "plain",
        "dataset_path": "./Bunny-v1_0-data/pretrain/bunny_pretrain_laion_2m.json",
        "image_folder": "./Bunny-v1_0-data/pretrain/images/",
        "lazy_preprocess": false,
        "is_multimodal": true,
        "image_aspect_ratio": "square"
    }
  }
  