{
    "tokenizer": {
        "pretrained_model_name_or_path": "kevin510/friday",
        "model_max_length": 2048,
        "padding_side": "right",
        "use_fast": true,
        "trust_remote_code": true
    },
    "model": {
        "pretrained_model_name_or_path": "microsoft/Phi-4-mini-reasoning",
        "device_map": "cuda",
        "cfg_vision_tower": {
            "pretrained_model_name_or_path": "google/siglip2-base-patch16-384",
            "s2_scales": "384,768",
            "use_s2": true,
            "pad_to_square": true,
            "model_params": { "device_map": "cuda" }
        },
        "cfg_vision_adapter": {
            "input_dim": 1536,
            "hidden_dim": 512,
            "output_dim": 3072,
            "num_layers": 2,
            "activation": "gelu",
            "device": "cuda",
            "checkpoint_path": null
        }
    },
    "data": {
        "data_path": "./Bunny-v1_0-data/pretrain/bunny_pretrain_laion_2m.json",
        "image_dir": "./Bunny-v1_0-data/pretrain/images/",
        "max_count": 250
    },
    "training": {
        "bits": 16,
        "mpt_attn_impl": "triton",
        "group_by_modality_length": false,
        "save_only_vision_adapter": true,
        "freeze_language_model": true,
        "freeze_vision_tower": true,
        "freeze_vision_adapter": false,

        
        "local_rank": -1,
        "remove_unused_columns": false,
        "optim": "adamw_torch",
        "fp16": false,
        "bf16": true,
        "tf32": true,
        "eval_strategy": "no",
        "output_dir": "./checkpoints-pretrain/friday",
        "num_train_epochs": 1,
        "per_device_train_batch_size": 8,
        "gradient_accumulation_steps": 4,
        "save_strategy": "steps",
        "save_steps": 24000,
        "save_total_limit": 1,
        "learning_rate": 5e-4,
        "weight_decay": 0.0,
        "warmup_ratio": 0.03,
        "lr_scheduler_type": "cosine",
        "logging_steps": 1,
        "gradient_checkpointing": true,
        "dataloader_num_workers": 4,
        "max_grad_norm": 1.0,
        "report_to": "wandb",
        "deepspeed": {
            "fp16": {
                "enabled": "auto",
                "loss_scale": 0,
                "loss_scale_window": 1000,
                "initial_scale_power": 16,
                "hysteresis": 2,
                "min_loss_scale": 1
            },
            "bf16": {
                "enabled": "auto"
            },
            "train_micro_batch_size_per_gpu": "auto",
            "train_batch_size": "auto",
            "gradient_accumulation_steps": "auto",
            "zero_optimization": {
                "stage": 2,
                "overlap_comm": true,
                "contiguous_gradients": true,
                "sub_group_size": 1e9,
                "reduce_bucket_size": "auto"
            }
        }
    }
  }
  